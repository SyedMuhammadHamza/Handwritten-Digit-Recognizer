{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "known-healthcare",
   "metadata": {},
   "source": [
    "#                                    Deep Neural Network From Scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    \"\"\"Initializing weitghs for all neurons between given input layer 'L_in'\n",
    "       and output layer 'L_out' to some initila value different from each \n",
    "       other hence avoiding 'PROBLEM OF SYMMETRIC WEIGHTS' \n",
    "       NOTE:this fucntion take layer l as L_in and layer l+1 as layer L_out and \n",
    "       return a matrix of shape (L_out)*(L_in +1) \n",
    "    \"\"\"\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Computes the sigmoid of z.\n",
    "    \"\"\"\n",
    "    g =1.0 / (1.0 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    \"\"\"Computes the gradient of sigmoid of z.\n",
    "    \"\"\"\n",
    "    g = np.zeros(z.shape)\n",
    "    g = sigmoid(z) * (1 - sigmoid(z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "    colOFonesFora1=np.ones([m,1], dtype = int)\n",
    "    a1=np.c_[colOFonesFora1,X]\n",
    "    z2=a1.dot(Theta1.T)\n",
    "    # Calculate activations in the second layer.\n",
    "    a2=sigmoid(z2)\n",
    "    colOfonesFora2=np.ones([m,1], dtype = int)\n",
    "    a2=np.c_[colOfonesFora2,a2]\n",
    "    z3=a2.dot(Theta2.T)\n",
    "    # Calculate the activation of the third layer.\n",
    "    a3=sigmoid(z3)\n",
    "\t#a3 is a 5000by10 matrix\n",
    "    #converts y into vecot if it was vector\n",
    "    y_matrix = y.reshape(-1)\n",
    "    '''we had vector of y with each value of vetor ith indicating \n",
    "    value of corresponding X in feature vector ith we have to convert \n",
    "    eaach value into row of 10 values '''\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    #prepariring regularization terms\n",
    "    temp1 = Theta1\n",
    "    temp2 = Theta2\n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n",
    "    #this (temp1[:, 1:] is chosing all of theta apart from first rwo of bais terms\n",
    "    J=(-1/ (m))*(np.sum((y_matrix*(np.log(a3)))+((1-y_matrix)*np.log(1-a3))))+reg_term\n",
    "    \n",
    "    #instead of using loop we are caculating delta vectoried\n",
    "    delta_3 = a3 - y_matrix\n",
    "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
    "    \n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2)\n",
    "    \n",
    "    Theta1_grad = (1 / m) * Delta1\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad = (1 / m) * Delta2\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
    "   \n",
    "    \n",
    "    # ================================================================\n",
    "    # Unroll gradients\n",
    "    # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    \"\"\"\n",
    "    Predict the label of an input given a trained neural network\n",
    "    Outputs the predicted label of X given the trained weights of a neural\n",
    "    network(Theta1, Theta2)\n",
    "    \"\"\"\n",
    "    # Useful values\n",
    "    m = X.shape[0]\n",
    "    num_labels = Theta2.shape[0]\n",
    "\n",
    "    # You need to return the following variables correctly\n",
    "    p = np.zeros(m)\n",
    "    h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n",
    "    h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n",
    "    p = np.argmax(h2, axis=1)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equal-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 63s 5us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD7CAYAAAAVQzPHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXSklEQVR4nO3de2xU1fYH8O8SxRcRKSpWQFBTq/gLvhDRi1oFDBc14AOVqEAk1kQwaNCAXjQaX/giUcQHUV5KwGsQQQ1BUguGiA2geC9QS9EELDYgvkBQuej6/dHj9uxjp53OnNfM/n6SZtaePTNnSZer55w5D1FVEBEVu4OSToCIKA5sdkTkBDY7InICmx0ROYHNjoicwGZHRE7Iq9mJyGARqRORLSIyKaykiJLG2i4+kutxdiLSDsBmAIMANABYA2CEqm4KLz2i+LG2i9PBeby3L4AtqvoVAIjIAgBDAWQsCBHhEczpsUtVj006iZRibRcwVZXmns9nM7YrgK994wbvOSoMW5NOIMVY20UonzW75rrn3/66iUglgMo8lkMUN9Z2Ecqn2TUA6O4bdwPwTfBFqjoDwAyAq/pUMFjbRSifzdg1AMpE5CQRaQ/gRgBLwkmLKFGs7SKU85qdqh4QkXEAlgFoB2Cmqm4MLTOihLC2i1POh57ktDCu6qfJOlXtk3QSxYK1nR5RfBtLRFQw2OyIyAlsdkTkBDY7InICmx0ROYHNjoicwGZHRE7I53QxIipi5557rjUeN26ciUeOHGnNzZ0718TTpk2z5j799NMIsms7rtkRkRPY7IjICWx2ROQEnhvbjHbt2lnjjh07Zv1e/36NI444wporLy838dixY625Z555xsQjRoyw5n799VcTT5kyxZp7+OGHs84tgOfGhqhQarslZ511ljX+8MMPrfFRRx2V1ef89NNP1rhz58555dVWPDeWiJzGZkdETijqQ09OPPFEa9y+fXsTX3jhhdZc//79TXz00Udbc9dee20o+TQ0NJj4+eeft+auvvpqE+/Zs8ea+/zzz028cuXKUHIhAoC+ffuaeOHChdZccPeNf5dXsEb3799v4uBma79+/UwcPAzF/76occ2OiJzAZkdETmCzIyInFN2hJ/6vz4NfnbflEJIw/PHHH9b41ltvNfHPP/+c8X2NjY3W+IcffjBxXV1dSNnx0JMwpfnQE/8hUOecc44198Ybb5i4W7du1pyIfQSHv1cE97099dRTJl6wYEHGz5k8ebI198QTT7SYey546AkROY3NjoicUHSHnmzbts3E3333nTUXxmZsTU2NNf7xxx+t8aWXXmri4Nfqr7/+et7LJ2qrV155xcTBs3NyFdwc7tChg4mDh0dVVFSYuHfv3qEsPxdcsyMiJ7DZEZET2OyIyAlFt8/u+++/N/G9995rzV155ZUm/uyzz6y54OlbfuvXrzfxoEGDrLm9e/da4zPOOMPE48ePbz1hopAFrzB8xRVXmDh4OIlfcF/bu+++a439V+b55ptvrDn//0/+Q6UA4LLLLstq+VFrdc1ORGaKyE4R2eB7rkRElotIvffYKdo0icLH2nZLNpuxswEMDjw3CUCVqpYBqPLGRIVmNljbzsjqDAoR6QngPVX9P29cB6BCVRtFpBTAClUtb+kzvPclepS5/+KDwas2+L+eHzNmjDV38803m3j+/PkRZRc7nkGB4qntls4caumim0uXLjVx8LCUSy65xBr7Dxt59dVXrblvv/024zJ+//13E+/bty/jMsK6MU/YZ1B0UdVG74MbARyXa2JEKcPaLlKRf0EhIpUAKqNeDlHcWNuFJdc1ux3eKj68x52ZXqiqM1S1DzeZqECwtotUrmt2SwCMAjDFe1wcWkYR2r17d8a54E1C/G677TYTv/nmm9Zc8MomVPAKorZPPfVUa+w/zCp4WuSuXbtMHLyizpw5c0wcvBLP+++/3+I4F4cffrg1njBhgolvuummvD+/JdkcejIfwGoA5SLSICJj0FQIg0SkHsAgb0xUUFjbbml1zU5VM505PCDkXIhixdp2S9GdQZGrhx56yMTBI9D9X48PHDjQmvvggw8izYvoT4ceeqiJ/WczAMCQIUNMHDysauTIkSZeu3atNRfcrIxb8KZYUeK5sUTkBDY7InICmx0ROaHobrgThlNOOcUa+09jCV6ZuLq62hr794lMnz7dmovz3zoLPF0sRHHUtv9m06tWrcr4ugED7O9Xkr6xuv90seD/A6tXrzbxRRddFMryeMMdInIamx0ROYGHnjTjyy+/tMajR4828axZs6y5W265JeP4yCOPtObmzp1r4uCR7EStmTp1qomDF8H0b6omvdkadNBBf61TJXnGEdfsiMgJbHZE5AQ2OyJyAvfZZWHRokUmrq+vt+b8+1EA+2v/xx9/3Jrr0aOHiR977DFrbvv27XnnScXFf4MowL4acfAQjiVLlsSRUk78++mCeftvZhU1rtkRkRPY7IjICWx2ROQE7rNrow0bNljj66+/3hpfddVVJg4ek3f77bebuKyszJoL3nybKHj5pfbt25t45077avHBK2jHzX/5Kf/l0oKCdz677777okrpb7hmR0ROYLMjIidwMzZPwaugvP766yYO3kj44IP/+ue++OKLrbmKigoTr1ixIrT8qDj99ttv1jju0w/9m60AMHnyZBP7b/4DAA0NDSZ+9tlnrbngTX6ixDU7InICmx0ROYHNjoicwH12bdS7d29rfN1111nj8847z8T+fXRBmzZtssYfffRRCNmRK5I4Pcx/ulpwv9wNN9xg4sWL7fuKX3vttZHmlS2u2RGRE9jsiMgJ3IxtRnl5uTUeN26cia+55hpr7vjjj8/6c/03HgkeKpDkFVwpnYJXI/aPhw0bZs2NHz8+9OXffffd1viBBx4wcceOHa25efPmmdh/U+404ZodETmh1WYnIt1FpFpEakVko4iM954vEZHlIlLvPXaKPl2i8LC23ZLNmt0BABNU9XQA/QCMFZFeACYBqFLVMgBV3piokLC2HdLqPjtVbQTQ6MV7RKQWQFcAQwFUeC+bA2AFgImRZBmB4L62ESNGmNi/jw4AevbsmdMy/DfMBuyrE6f5yrKuSHttB6/q6x8H6/f555838cyZM6257777zsT+G20D9t3wzjzzTGuuW7du1njbtm0mXrZsmTX34osv/v0/IGXatM9ORHoCOBtADYAuXrH8WTTHhZ4dUUxY28Uv629jRaQDgIUA7lLV3cFvilp4XyWAytzSI4oea9sNElxVbvZFIocAeA/AMlWd6j1XB6BCVRtFpBTAClUtb+VzWl9YiLp06WKNe/XqZeIXXnjBmjvttNNyWkZNTY01fvrpp00cPJI8ZYeXrFPVPkknkbQ01/bw4cOt8fz587N6344dO6zx7t27TRy8aGxLVq9ebY2rq6tN/OCDD2b9OXFT1Wb/WmXzbawAeA1A7Z/F4FkCYJQXjwKwOPheojRjbbslm83YfwC4BcB/RWS999z9AKYA+LeIjAGwDcDw5t9OlFqsbYdk823sKgCZdmIMyPA8Ueqxtt2S1T670BYWwX6NkpISa/zKK6+Y2H+VBgA4+eSTc1rGxx9/bOLglVaDX8H/8ssvOS0jAdxnF6Ioajt46Mdbb71lYv/VdZrJxRq39P+4/7CUBQsWWHNRnIIWh5z32RERFQM2OyJyQkFsxp5//vnW2H/hwL59+1pzXbt2zWUR2Ldvn4n9R6MDwOOPP27ivXv35vT5KcTN2BDFcVhVaWmpif33IAbsG960tBn73HPPWXMvvfSSibds2RJKnknjZiwROY3NjoicwGZHRE4oiH12U6ZMscbBm31kErypzXvvvWfiAwcOWHP+Q0qCN74uUtxnF6K4T4WkzLjPjoicxmZHRE4oiM1YigQ3Y0PE2k4PbsYSkdPY7IjICWx2ROQENjsicgKbHRE5gc2OiJzAZkdETmCzIyInsNkRkRPY7IjICdncSjFMuwBsBXCMF6eBq7n0iGk5rtgFYC/SU0uAm7Wdsa5jPTfWLFRkbVrOy2QuFJa0/f7SlE8acuFmLBE5gc2OiJyQVLObkdBym8NcKCxp+/2lKZ/Ec0lknx0RUdy4GUtEToi12YnIYBGpE5EtIjIpzmV7y58pIjtFZIPvuRIRWS4i9d5jp5hy6S4i1SJSKyIbRWR8kvlQfpKsbdZ1dmJrdiLSDsB0AP8E0AvACBHpFdfyPbMBDA48NwlAlaqWAajyxnE4AGCCqp4OoB+Asd6/R1L5UI5SUNuzwbpuVZxrdn0BbFHVr1R1P4AFAIbGuHyo6kcAvg88PRTAHC+eA2BYTLk0quqnXrwHQC2ArknlQ3lJtLZZ19mJs9l1BfC1b9zgPZe0LqraCDT9ogAcF3cCItITwNkAatKQD7VZGms78TpKW13H2eyau+OP818Fi0gHAAsB3KWqu5POh3LC2g5IY13H2ewaAHT3jbsB+CbG5WeyQ0RKAcB73BnXgkXkEDQVxDxVfTvpfChnaaxt1nVAnM1uDYAyETlJRNoDuBHAkhiXn8kSAKO8eBSAxXEsVEQEwGsAalV1atL5UF7SWNus6yBVje0HwBAAmwF8CeBfcS7bW/58AI0A/oemv8ZjAHRG07dD9d5jSUy59EfTps5/AKz3foYklQ9/8v59JlbbrOvsfngGBRE5gWdQEJET2OyIyAl5NbukT/8iigpru/jkvM/OO0VmM4BBaNopugbACFXdFF56RPFjbRenfO5BYU6RAQAR+fMUmYwFISL8NiQ9dqnqsUknkVKs7QKmqs0d5J3XZmwaT5Gh7G1NOoEUY20XoXzW7LI6RUZEKgFU5rEcorixtotQPs0uq1NkVHUGvEsyc1WfCgRruwjlsxmbxlNkiMLA2i5COa/ZqeoBERkHYBmAdgBmqurG0DIjSghruzjFeroYV/VTZZ2m5AbKxYC1nR5RfBtLRFQw2OyIyAlsdkTkBDY7InICmx0ROYHNjoicwGZHRE5gsyMiJ7DZEZET2OyIyAlsdkTkhHwu8UQhGjBggInnzZtnzV1yySUmrquriy0nomxNnjzZxA8//LA1d9BBf61TVVRUWHMrV66MNC8rj9iWRESUIDY7InJCQWzGXnzxxda4c+fOJl60aFHc6UTivPPOM/GaNWsSzISodaNHj7bGEydONPEff/yR8X1xXlIuiGt2ROQENjsicgKbHRE5oSD22QW/ri4rKzNxoe6z838dDwAnnXSSiXv06GHNiTR7lWmixARr9LDDDksok+xxzY6InMBmR0ROKIjN2JEjR1rj1atXJ5RJeEpLS63xbbfdZuI33njDmvviiy9iyYmoJQMHDjTxnXfemfF1wXq98sorTbxjx47wE8sS1+yIyAlsdkTkBDY7InJCQeyzCx6mUQxeffXVjHP19fUxZkLUvP79+1vjWbNmmbhjx44Z3/f0009b461bt4abWI5a7SIiMlNEdorIBt9zJSKyXETqvcdO0aZJFD7WtluyWWWaDWBw4LlJAKpUtQxAlTcmKjSzwdp2Rqubsar6kYj0DDw9FECFF88BsALARISod+/eJu7SpUuYH50KLW0GLF++PMZM3JVUbReKUaNGWeMTTjgh42tXrFhh4rlz50aVUl5y3RnWRVUbAcB7PC68lIgSxdouUpF/QSEilQAqo14OUdxY24Ul1zW7HSJSCgDe485ML1TVGaraR1X75LgsojixtotUrmt2SwCMAjDFe1wcWkaeIUOGmPjwww8P++MT4d/36L/KSdD27dvjSIeaF3ltp9UxxxxjjW+99VZr7L8C8Y8//mjNPfroo5HlFZZsDj2ZD2A1gHIRaRCRMWgqhEEiUg9gkDcmKiisbbdk823siAxTAzI8T1QQWNtuSe0ZFOXl5RnnNm7cGGMm4XnmmWdMHDycZvPmzSbes2dPbDmR23r27GnihQsXZv2+adOmWePq6uqwUopM8Z2HRUTUDDY7InICmx0ROSG1++xakqabSB911FHWePDgv061vPnmm625yy+/POPnPPLIIyYOfq1PFBV/vfpP0WxOVVWViZ977rnIcooK1+yIyAlsdkTkhILcjC0pKcnpfWeeeaaJg/di9d9MpFu3btZc+/btTXzTTTdZc8ELi/7yyy8mrqmpseZ+++03Ex98sP1Pv27duhZzJwrDsGHDrPGUKZmPmV61apU19l8F5aeffgo1rzhwzY6InMBmR0ROYLMjIiekdp+df9+XqlpzL7/8sonvv//+rD/T/9V6cJ/dgQMHTLxv3z5rbtOmTSaeOXOmNbd27VprvHLlShMHbwjc0NBg4uCVXHgjbIpKrqeEffXVV9Y4yRtch4FrdkTkBDY7InICmx0ROSG1++zuuOMOEwdvsnvhhRfm9Jnbtm0z8TvvvGPN1dbWmviTTz7J6fODKivt2xMce+yxJg7uDyGKysSJf90czX+14da0dAxeIeKaHRE5gc2OiJyQ2s1YvyeffDLpFHIyYEDmq3u35RAAorY466yzrHFLV9vxW7zYvrdQXV1dWCmlAtfsiMgJbHZE5AQ2OyJyQkHssytGixYtSjoFKlIffPCBNe7UqVPG1/oPsxo9enRUKaUC1+yIyAlsdkTkBG7GEhWZzp07W+OWzpp48cUXTfzzzz9HllMatLpmJyLdRaRaRGpFZKOIjPeeLxGR5SJS7z1m3jFAlEKsbbdksxl7AMAEVT0dQD8AY0WkF4BJAKpUtQxAlTcmKiSsbYe02uxUtVFVP/XiPQBqAXQFMBTAHO9lcwAMiyhHokiwtt3Spn12ItITwNkAagB0UdVGoKloROS48NMrLv6rI5966qnWXFhXWqHcFHptz5o1y8TBO9615OOPP44inVTKutmJSAcACwHcpaq7g5c1b+F9lQAqW30hUUJY227I6k+AiByCpmKYp6pve0/vEJFSb74UwM7m3quqM1S1j6r2CSNhojCxtt3R6pqdNP2Zew1ArapO9U0tATAKwBTvcXEzbycf/42D2rKpQdEo5NoOXtnEf5P34KEm+/fvN/H06dOtuUK/iU5bZLMZ+w8AtwD4r4is9567H02F8G8RGQNgG4DhkWRIFB3WtkNabXaqugpApp0YmS/YRpRyrG23cFuKiJzA08UScsEFF1jj2bNnJ5MIFaSjjz7aGh9//PEZX7t9+3YT33PPPVGllHpcsyMiJ7DZEZETuBkbo2wPViWi8HHNjoicwGZHRE5gsyMiJ3CfXYSWLl1qjYcP54H4FI4vvvjCGvuvXtK/f/+40ykIXLMjIiew2RGRE8R/JY7IFyYS38KoNet4aaLwsLbTQ1WbPcaLa3ZE5AQ2OyJyApsdETmBzY6InMBmR0ROYLMjIiew2RGRE9jsiMgJbHZE5AQ2OyJyQtxXPdkFYCuAY7w4DVzNpUdMy3HFLgB7kZ5aAtys7Yx1Heu5sWahImvTcl4mc6GwpO33l6Z80pALN2OJyAlsdkTkhKSa3YyEltsc5kJhSdvvL035JJ5LIvvsiIjixs1YInJCrM1ORAaLSJ2IbBGRSXEu21v+TBHZKSIbfM+ViMhyEan3HjvFlEt3EakWkVoR2Sgi45PMh/KTZG2zrrMTW7MTkXYApgP4J4BeAEaISK+4lu+ZDWBw4LlJAKpUtQxAlTeOwwEAE1T1dAD9AIz1/j2SyodylILang3WdaviXLPrC2CLqn6lqvsBLAAwNMblQ1U/AvB94OmhAOZ48RwAw2LKpVFVP/XiPQBqAXRNKh/KS6K1zbrOTpzNriuAr33jBu+5pHVR1Uag6RcF4Li4ExCRngDOBlCThnyozdJY24nXUdrqOs5m19wdf5z/KlhEOgBYCOAuVd2ddD6UE9Z2QBrrOs5m1wCgu2/cDcA3MS4/kx0iUgoA3uPOuBYsIoegqSDmqerbSedDOUtjbbOuA+JsdmsAlInISSLSHsCNAJbEuPxMlgAY5cWjACyOY6EiIgBeA1CrqlOTzofyksbaZl0HqWpsPwCGANgM4EsA/4pz2d7y5wNoBPA/NP01HgOgM5q+Har3HktiyqU/mjZ1/gNgvfczJKl8+JP37zOx2mZdZ/fDMyiIyAk8g4KInMBmR0ROYLMjIiew2RGRE9jsiMgJbHZE5AQ2OyJyApsdETnh/wGmetwHakoisQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 100.000000\n",
      "Test Set Accuracy: 98.460000\n"
     ]
    }
   ],
   "source": [
    " #load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "'''The training dataset is structured as a 3-dimensional array of instance,\n",
    " image width and image height. For a multi-layer perceptron model we must \n",
    " reduce the images down into a vector of pixels. In this case the 28Ã—28 \n",
    " sized images will be 784 pixel input values.\n",
    " We can also reduce our memory requirements by forcing the precision of \n",
    " the pixel values to be 32 bit, the default precision used by Keras anyway.'''\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]#num_pixels=row*column\n",
    "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "\n",
    "'''The pixel values are gray scale between 0 and 255. It is almost always\n",
    " a good idea to perform some scaling of input values when using neural \n",
    " network models. Because the scale is well known and well behaved, we\n",
    " can very quickly normalize the pixel values to the range 0 and 1 by \n",
    " dividing each value by the maximum of 255.'''\n",
    " \n",
    " # normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[0]\n",
    "\n",
    "input_layer_size=num_pixels\n",
    "hidden_layer_size=800\n",
    "output_layer_size=10\n",
    "\n",
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size,output_layer_size)\n",
    "\n",
    "# Unroll parameters\n",
    "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)\n",
    "lambda_ = 0.5\n",
    "\n",
    "J, _ = nnCostFunction(initial_nn_params, input_layer_size, hidden_layer_size,\n",
    "                      output_layer_size,X_train,y_train, lambda_)\n",
    "\n",
    "options= {'maxiter': 400}\n",
    "#  You should also try different values of lambda\n",
    "#lambda_ = 3\n",
    "\n",
    "# Create \"short hand\" for the cost function to be minimized\n",
    "costFunction = lambda p: nnCostFunction(p, input_layer_size,\n",
    "                                        hidden_layer_size,\n",
    "                                        output_layer_size,X_train,y_train, lambda_)\n",
    "\n",
    "# Now, costFunction is a function that takes in only one argument\n",
    "# (the neural network parameters)\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_nn_params,\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# get the solution of the optimization\n",
    "nn_params = res.x\n",
    "        \n",
    "# Obtain Theta1 and Theta2 back from nn_params\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                    (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                    (output_layer_size, (hidden_layer_size + 1)))\n",
    "\n",
    "pred = predict(Theta1, Theta2, X_train)\n",
    "print('Training Set Accuracy: %f' % (np.mean(pred == y_train) * 100))\n",
    "pred = predict(Theta1, Theta2, X_test)\n",
    "print('Test Set Accuracy: %f' % (np.mean(pred == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-transsexual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
